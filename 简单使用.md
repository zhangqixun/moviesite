# 服务器

|  名称  |     内网ip     |    外网ip     |
| :----: | :------------: | :-----------: |
| cloud1 | 172.26.154.146 | 39.99.134.147 |
| cloud2 | 172.26.240.217 | 39.98.134.47  |
| cloud3 | 172.26.154.144 | 39.99.134.117 |
| cloud4 | 172.26.154.145 | 39.99.140.220 |
| cloud5 | 172.26.240.216 | 39.100.90.186 |



# 节点分配

|           |                 | cloud1 | cloud2 | cloud3 | cloud4 | cloud5 |
| :-------: | :-------------: | :----: | :----: | :----: | :----: | :----: |
| Zookeeper | QuorumPeerMain  |   √    |   √    |   √    |        |        |
|   HDFS    |    NameNode     |   √    |   √    |        |        |        |
|           |   JournalNode   |   √    |   √    |   √    |        |        |
|           |    DataNode     |   √    |   √    |   √    |        |        |
|           |      ZFKC       |   √    |   √    |        |        |        |
|   YARN    | ResourceManager |   √    |   √    |        |        |        |
|           |   NodeManager   |   √    |   √    |   √    |   √    |   √    |
|   Hbase   |     HMaster     |   √    |   √    |        |        |        |
|           |  HRegionServer  |   √    |   √    |   √    |        |        |
|           |  ThriftServer   |   √    |   √    |   √    |        |        |
|   Kafka   |     Worker      |        |        |   √    |   √    |   √    |
|   Spark   |     Broker      |   √    |   √    |   √    |   √    |   √    |
|  MongoDB  |        -        |        |        |   √    |   √    |   √    |
|  Django   |        -        |        |        |        |   √    |   √    |
|   Redis   |        -        |        |        |        |   √    |   √    |
|   Nginx   |        -        |        |        |        |   √    |   √    |



# 简单使用

1. 在 `cloud1`、`cloud2`、`cloud3` 启动 `Zookeeper`

```
zkServer.sh start
```

2. 在 `cloud1` 启动 `HDFS` 集群

```
start-dfs.sh
```

3. 在 `cloud1`、`cloud2`、`cloud3` 启动 `journalnode`

```
hdfs --daemon start journalnode
```

4. 在 `cloud2` 启动 `YARN` 集群

```
start-yarn.sh
```

5. 在 `cloud1` 启动 `Hbase` 集群

```
start-hbase.sh
```

6. 在 `cloud2` 启动 `hmaster`

```
hbase-daemon.sh start master
```

7. 在 `cloud1`、`cloud2`、`cloud3` 启动 `thrift`

```
hbase-daemon.sh start thrift
```

8. 在 `cloud3`、`cloud4`、`cloud5` 启动 `Kafka`

```
kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
```

9. 在 `cloud3`、`cloud4`、`cloud5` 启动 `MongoDB`

```
mongod -f $MONGODB_HOME/mongo.conf
```

10. 在 `cloud4`、`cloud5` 启动 `Redis`

```
redis-server /$REDIS_HOME/redis.conf
```

11. 在 `cloud4`、`cloud5` 通过 `uWSGI` 启动 `Django`

```
cd /usr/cloud302/moviesite
source bin/activate
uwsgi --ini /usr/cloud302/moviesite/uwsgi.ini
```

12. 在 `cloud4`、`cloud5` 启动 `Nginx`

```
nginx
```

13. 此时可以运行每天一次的离线推荐服务或长期运行的离线推荐服务。

```
spark-submit  --master yarn --deploy-mode client --jars /usr/cloud302/spark-streaming-kafka.jar,/usr/cloud302/mongo-spark-connector.jar /usr/cloud302/offline.py
spark-submit  --master yarn --deploy-mode client --jars /usr/cloud302/spark-streaming-kafka.jar,/usr/cloud302/mongo-spark-connector.jar /usr/cloud302/online.py
```

