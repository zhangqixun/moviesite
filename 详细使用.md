# Zookeeper

## 启动 `Zookeeper` 服务

在每台 `Zookeeper` 服务器上

```
zkServer.sh start
```

## 查看 `Zookeeper` 状态

```
zkServer.sh status
```

## 客户端连接 `Zookeeper`

```
zkCli.sh -server cloud1:6181
```

## 关闭 `Zookeeper` 服务

在每台 `Zookeeper` 服务器上

```
zkServer.sh stop
```



# HDFS(HA)


## 首次使用初始化

1. 启动 `Zookeeper` 集群

2. 在某台 `namenode` 服务器上，格式化 `namenode`

```
hdfs namenode -format
```

并将格式化后的数据拷贝到其它 `namenode` 服务器上，如：

```
scp -r $HADOOP_HOME/hdfs/name cloud2:/$HADOOP_HOME/hdfs
```

3. 在某台 `namenode` 服务器上，初始化 `ZKFC`

```
hdfs zkfc -formatZK
```


## 启动 `HDFS(HA)` 服务
1. 启动 `Zookeeper` 集群

2. 在每台 `journalnode` 服务器上，启动 `journalnode`

```
hdfs --daemon start journalnode
```
3. 在某台 `namenode` 服务器上，启动 `HDFS` 集群

```
start-dfs.sh
```

## 查看 `namenode` 状态

```
hdfs haadmin -getServiceState nn1
hdfs haadmin -getServiceState nn2

```

## 关闭 `HDFS(HA)` 服务

1. 在某台 `namenode` 服务器上，关闭`HDFS` 集群

```
stop-dfs.sh
```

2. 在每台服务器上，关闭 `journalnode`

```
hdfs --daemon stop journalnode
```

3. 关闭 `Zookeeper` 集群

## 使用 `hdfs dfs`

```
hdfs dfs -ls /
hdfs dfs -put /file /
hdfs dfs -get /file /
hdfs dfs -mkdir /dir
hdfs dfs -text /file
hdfs dfs -rm /file
```

## 使用 `pyhdfs`

```python
import pyhdfs
fs = pyhdfs.HdfsClient('cloud1:9870,cloud2:9870')
fs.listdir('/')
fs.copy_from_local('/localfile','/dest')
fs.copy_to_local('/srcfile','/local')
fs.delete('/filename')
```



# YARN(HA)

## 启动 `YARN(HA)` 服务

1. 启动 `zookeeper` 集群

2. 在某台 `resourcemanager` 服务器上，启动 `YARN` 集群

```
start-yarn.sh
```


## 查看 `resourcemanager` 状态

```
yarn rmadmin -getServiceState rm1
yarn rmadmin -getServiceState rm2
```

## 关闭 `YARN(HA)` 服务

1. 在某台 `resourcemanager` 服务器上，关闭 `YARN` 集群

```
stop-yarn.sh
```

2. 关闭 `zookeeper` 集群



# Hbase(HA)

## 启动 `Hbase(HA)` 服务

1. 在某台 `hmaster` 服务器上

```
start-hbase.sh
```
2. 在其余 `hmaster` 服务器上

```
hbase-daemon.sh start master
```

3. 在所有 `hbase` 服务器上

```

```



## 关闭 `Hbase(HA)` 服务

在某台 `hmaster` 服务器上

```
stop-hbase.sh
```

## 终端 `hbase shell` 操作

1. 进入hbase console命令
```
hbase shell 
```
2. 建表，表名为test，列族名为cf
```
hbase(main):005:0> create 'test','cf'
```
3. 停用表
```
disable 'test'
```
4. 删除表(需要先停用)
```
drop 'test'
```
5. 插入
```
put <table>,<rowkey>,<family:column>,<value>,<timestamp>
#若行键和列都已存在，则把其置为最新一个版本
```
6. 删除
```
delete <table>, <rowkey>,  <family:column> , <timestamp>
```

7. 扫描全表，或，指定过滤条件，返回对应行

```
scan 'hbase',{COLUMNS=> 'cf: col_1', LIMIT => 1, ...}
```

8. count统计表中记录数

```
count 'hbase', {INTERVAL => 100, CACHE => 500}
```



# Kafka(HA)

## 启动 `kafka(HA)` 服务
在每台 `Kafka` 服务器上
```
kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
```


## 关闭 `Kafka(HA)` 服务

在每台 `Kafka` 服务器上
```
kafka-server-stop.sh
```

## 终端 `kafka` 的使用

1. 创建 `topic`

```
kafka-topics.sh --create --zookeeper cloud1:6181,cloud2:6181,cloud3:6181 --replication-factor 3 --partitions 1 --topic test
```

2. 查看 `topic`

```
kafka-topics.sh --describe --zookeeper cloud1:6181,cloud2:6181,cloud3:6181 --topic test
```

3. 生产者 

```
kafka-console-producer.sh --broker-list cloud3:9092,cloud4:9092,cloud5:9092 --topic test
```

4. 消费者

```
kafka-console-consumer.sh --bootstrap-server cloud3:9092,cloud4:9092,cloud5:9092 --from-beginning --topic test
```

## `kafka-python` 的使用

1. 生产者


```python
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers='cloud3:9092,cloud4:9092,cloud5:9092')
producer.send('world', b'text')
```

2. 消费者

```python
from kafka import KafkaConsumer
consumer=KafkaConsumer('world', bootstrap_servers='cloud3:9092,cloud4:9092,cloud5:9092')
for each in consumer:
    print(each)
```



# Spark


## 提交任务到本地 `Spark`

1. 提交 `Spark` 任务

```
spark-submit pi.py 10
```

2. 提交 `Spark Streaming` 任务

```
spark-submit --jars spark-streaming-kafka.jar,mongo-spark-connector.jar kafka_wordcount.py cloud1:6182,cloud2:6181,cloud3:6181 test
```


## 提交任务到 `YARN` 集群

1. 提交 `Spark` 任务

```
spark-submit --master yarn --deploy-mode cluster pi.py 10
spark-submit --master yarn --deploy-mode client pi.py 10
```
2. 提交 `Spark Streaming` 任务

```
spark-submit  --master yarn --deploy-mode cluster --jars spark-streaming-kafka.jar,mongo-spark-connector.jar kafka_wordcount.py cloud1:6182,cloud2:6181,cloud3:6181 test
spark-submit  --master yarn --deploy-mode client --jars spark-streaming-kafka.jar,mongo-spark-connector.jar kafka_wordcount.py cloud1:6182,cloud2:6181,cloud3:6181 test
```



# MongoDB(Replica Set)

## 启动 `MongoDB(Replica Set)` 服务
在每台 `MongoDB` 服务器上

```
mongod -f $MONGODB_HOME/mongo.conf
```
## 查看 `MongoDB(Replica Set)` 状态

1. 查看本地 `MongoDB` 状态

```
ps -ef | grep mongo
```

2. 查看 `MongoDB(Replica Set)` 状态

```
mongostat --host cloud3:8018,cloud4:8018,cloud5:8018
```


## 关闭 `MongoDB(Replica Set)` 服务


```
mongod -shutdown -f $MONGODB_HOME/mongo.conf
```

4. `MongoDB` 客户端

```
mongo -host cloud/cloud3:8018,cloud4:8018,cloud5:8018
```

```
show dbs
use db_name
show tables
db.db_name.find().pretty()
db.db_name.find({'cil':'...'},{'show_col':1})
db.db_name.insert({'col':'...'})
db.col.update({'col':'...'},{$set:{'col':'...'}},{multi:true})
db.col.remove({'col':'...'})
```

5. `pymongo` 的使用

```python
import pymongo
client = pymongo.MongoClient('cloud/cloud3:8018,cloud4:8018,cloud:8018')
db = client['db_name']
print(db.list_collection_names())
table = db["table_name"]
for each in table.find():
    print(each)
table.insert_one({'col':'...'})
table.insert_many([...])
mycol.update_one({'col':'...'}, { '$set': {'col':'...'}})
mycol.delete_one({'col':'...'})
```



# Redis

## 启动 `Redis` 服务

```
redis-server /$REDIS_HOME/redis.conf
```

## 关闭 `Redis` 服务

```
redis-cli shutdown
```



# Django

## 首次使用初始化

1. 创建并激活 `python3` 虚拟环境

```
cd /usr/cloud302/moviesite
virtualenv . -p python3
source bin/activate
```


2. 安装 `python` 库


```
pip install https://codeload.github.com/sshwsfc/xadmin/zip/django2
pip install -r requirements.txt
```

3. 创建数据库表单

```
python manage.py makemigrations
python manage.py migrate
```

4. 创建 `Django` 超级用户

```
python manage.py createsuperuser
```


## 使用 `Django` 服务


1. 激活 `python3` 虚拟环境

```
cd /usr/cloud302/moviesite
source bin/activate
```

2.  启动 `Django` 服务

```
python manage.py runserver 0:8004
```
3. 关闭 `Django` 服务

```
Ctrl+C
```



# uWSGI

## 通过 `uWSGI` 使用 `Django` 服务


1.  激活 `python3` 虚拟环境

```
cd /usr/cloud302/moviesite
source bin/activate
```

2. 启动 `uWSGI` 服务

```
uwsgi --ini /usr/cloud302/uwsgi.ini
```
3. 关闭 `uWSGI` 服务

```
uwsgi --stop /usr/cloud302/uwsgi.pid
```



# Nginx

## 启动 `Nginx` 服务

```
nginx
```

## 关闭 `Nginx` 服务

```
nginx -s stop
```

